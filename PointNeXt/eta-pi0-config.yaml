
dist_backend: 'nccl' #For Nvidia
world_size: 1        #Number of processes/GPUs
local_rank: 0 
launcher: null 
deterministic: False
epochs: 100
lr: 0.001 # was 0.001
sched: 'cosine'
save_freq: 5

# basic config
common:
  seed: 0
  tensorboard: False
  wandb: 
    use_wandb: False 
  exp_name: 'pointnext_eta-pi0-classification'
  task_name: 'classification_events'

root_dir: 'eta-pi0-classification'


train:
  print_freq: 1
  num_workers: 0
  batch_size: 64
  num_epochs: 100
  val_freq: 2
  step_per_update: 1
  start_epoch: 0
  sched_on_epoch: True
  save_freq: 1


#dataset config
dataset:
  common:
    NAME: 'create_event_dataset'
    num_points: 1028 # Be careful when changing
    h5_file_path: '../../eta-pi-data/eta-pi0-update.h5'
    max_samples: 15000
    train_split: 0.7
    val_split: 0.15
    test_split: 0.15
  train:
    transforms: []
  val:
    batch_size: 32
  test:
    batch_size: 32


#model config
model:
  NAME: 'ClassificationModelWrapper'
  encoder_args:
    NAME: 'PointNextEncoder' # PointNeXt/openpoints/models/backbone/pointnext.py
    blocks: [1, 4, 7, 4]
    strides: [4, 4, 4, 4]
    sa_layers: 1 
    sa_use_res: True 
    width: 32
    in_channels: 4 # Was 3
    expansion: 4
    radius: 0.1
    nsample: 32
    aggr_args:
      feature_type: 'dp_fj'
      reduction: 'max'
    group_args:
      NAME: 'ballquery'
      normalize_dp: False
    conv_args: {}
    act_args:
      act: 'relu' # was relu
    norm_args:
      norm: 'bn' # group norm # bn: nn.BatchNorm2d # from openpoints/models/layers/norm.py
    # decoder_args:
    #   NAME: PointNextDecoder
    sampler: 'fps'
    radius_scaling: 2
    nsample_scaling: 1
  head_args: 
    NAME: 'ClsHead' # From openpoints/models/classification/cls_base.py
    num_classes: 1
    in_channels: 4
    act_args:
      act: 'sigmoid'
    mlps: [256, 128, 64] # [256, 128]
    # dropout: 0
    # global_feat: 'max'
    # point_dim: 1
    
    # NAME: 'RegressionHead'
    # encoder_out_channels: 512 
    # out_dim: 1 #single regression output (opang)
    # mlp_channels: [256, 128] # MLP layers within the head
    # norm_args:
    #   norm: 'bn'
    # act_args:
    #   act: 'sigmoid'


# Optimizer config
optimizer:
  NAME: 'AdamW'
  lr: 0.001 # Was 0.001
  weight_decay: 0.0001 # Was 0.0001

# Scheduler config
scheduler:
  NAME: 'CosineAnnealingLR'
  T_max: 100 # Should match num_epochs in train section
  eta_min: 0.00001 

# Loss config
loss:
  NAME: 'BCELoss' #Binary Cross Entropy for classification
  reduction: 'mean'